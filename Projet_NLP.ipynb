{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Projet_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Na3pHouZ01S"
      },
      "source": [
        "# Importation des librairies et données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvD6KRau_STo",
        "outputId": "fa57abd9-7afe-4561-b716-caa00702c8d4"
      },
      "source": [
        "from keras.datasets import imdb\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from keras.layers import LSTM, Activation, Dropout, Dense, Input, Masking, Embedding, Flatten\r\n",
        "from keras.layers.embeddings import Embedding\r\n",
        "from keras.models import Model\r\n",
        "import string\r\n",
        "import re\r\n",
        "from nltk.tokenize import word_tokenize\r\n",
        "from nltk.stem import WordNetLemmatizer\r\n",
        "from nltk.corpus import wordnet\r\n",
        "from sklearn import metrics\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from sklearn.preprocessing import LabelBinarizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import keras\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import nltk\r\n",
        "\r\n",
        "from sklearn import linear_model\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.preprocessing.text import Tokenizer\r\n",
        "from keras.preprocessing.sequence import pad_sequences\r\n",
        "import requests\r\n",
        "import json\r\n",
        "\r\n",
        "nltk.download('punkt')\r\n",
        "nltk.download('stopwords')\r\n",
        "nltk.download('wordnet')\r\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NotBIx-U_rz4",
        "outputId": "781cbc94-7912-494f-c702-2ede9f8be19e"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/', force_remount=True)"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q2PaqXo9kkZ"
      },
      "source": [
        "#Découpage des données"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWyXsJ6TK83k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1b88a52-09d1-4709-a9df-25ced2e1c4ee"
      },
      "source": [
        "data = pd.read_csv('gdrive/MyDrive/NLP_Projet/data_NLP.csv',encoding='ISO-8859-1',header=None,names=['feeling','ids','date','?','utilisateur','text'])\r\n",
        "data.drop(['ids','date','?','utilisateur'], axis=1, inplace=True)  #j'enlève les colonnes que je n'utilise pas\r\n",
        "print(data)\r\n",
        "data=data[799000:801000]  #on réduis la quantité de tweets (1000 tweets négatifs et 1000 positifs)\r\n",
        "print(data)\r\n",
        "\r\n"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         feeling                                               text\n",
            "0              0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
            "1              0  is upset that he can't update his Facebook by ...\n",
            "2              0  @Kenichan I dived many times for the ball. Man...\n",
            "3              0    my whole body feels itchy and like its on fire \n",
            "4              0  @nationwideclass no, it's not behaving at all....\n",
            "...          ...                                                ...\n",
            "1599995        4  Just woke up. Having no school is the best fee...\n",
            "1599996        4  TheWDB.com - Very cool to hear old Walt interv...\n",
            "1599997        4  Are you ready for your MoJo Makeover? Ask me f...\n",
            "1599998        4  Happy 38th Birthday to my boo of alll time!!! ...\n",
            "1599999        4  happy #charitytuesday @theNSPCC @SparksCharity...\n",
            "\n",
            "[1600000 rows x 2 columns]\n",
            "        feeling                                               text\n",
            "799000        0  CAN'T BEAT LIVE MUSIC, WISH I COULD SING BUT I...\n",
            "799001        0  Charlie lost an angel today   Very sad   http:...\n",
            "799002        0                           at work, and very bored \n",
            "799003        0  It's weird how celebrities go in threes. Carra...\n",
            "799004        0  @adelate Farrah's dead? Had no idea.. RIP Farr...\n",
            "...         ...                                                ...\n",
            "800995        4  I have this strange desire to go to confession...\n",
            "800996        4             @i_reporter answer sent in dm. try it \n",
            "800997        4  @brooklynunion cuz ur 3pm is my 9am and Id be ...\n",
            "800998        4  @littrellfans Its all good. Just figured you w...\n",
            "800999        4                   @nicolerichie Yea I remember it \n",
            "\n",
            "[2000 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZRAQWqz-DCt"
      },
      "source": [
        "# Utilisation de la classe tokenizer de keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MLHojs_-LGgg",
        "outputId": "2345a995-c165-40c7-f6e8-9194894b7d9b"
      },
      "source": [
        "# La classe tokenizer de keras permet de vectoriser le text corpus.\r\n",
        "tokenizer = Tokenizer(num_words=20000, split=\" \")\r\n",
        "tokenizer.fit_on_texts(data[\"text\"].values)\r\n",
        "\r\n",
        "\r\n",
        "X= tokenizer.texts_to_sequences(data[\"text\"].values) # convertir les tokens du texte en séquence d'integers\r\n",
        "X = pad_sequences(X) \r\n",
        "print(X[:33])\r\n",
        "print(X.shape)"
      ],
      "execution_count": 266,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   0    0    0 ...   21    1  100]\n",
            " [   0    0    0 ...  840  841 1750]\n",
            " [   0    0    0 ...    7   93  411]\n",
            " ...\n",
            " [   0    0    0 ...   15   63   22]\n",
            " [   0    0    0 ...  456   19 1804]\n",
            " [   0    0    0 ...    2 1127   14]]\n",
            "(2000, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsiW1yoXvK_5",
        "outputId": "df826e8a-5561-4147-d46f-491e496ad6c0"
      },
      "source": [
        "\r\n",
        "Y=pd.get_dummies(data[\"feeling\"]).values    # renvoie [0 1] pour les positifs et [1 0] pour les négatifs\r\n",
        "print(Y)                  \r\n",
        "\r\n"
      ],
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 0]\n",
            " [1 0]\n",
            " [1 0]\n",
            " ...\n",
            " [0 1]\n",
            " [0 1]\n",
            " [0 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIAUZEifAGd8"
      },
      "source": [
        "#RNN Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLyRJpb5AHO8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7061e5c-0a11-4d2a-ef70-4bb47bf0d8c5"
      },
      "source": [
        "\r\n",
        "model = Sequential()\r\n",
        "\r\n",
        "\r\n",
        "model.add(Embedding(20000, 256, input_length=X.shape[1]))\r\n",
        "model.add(Dropout(0.3))\r\n",
        "model.add(LSTM(256,return_sequences=False,dropout=0.3,recurrent_dropout=0.2))\r\n",
        "model.add(Dense(2, activation=\"sigmoid\"))\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "x_train,x_test,y_train,y_test = train_test_split(X,Y,random_state=0)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_28 (Embedding)     (None, 32, 256)           5120000   \n",
            "_________________________________________________________________\n",
            "dropout_28 (Dropout)         (None, 32, 256)           0         \n",
            "_________________________________________________________________\n",
            "lstm_28 (LSTM)               (None, 256)               525312    \n",
            "_________________________________________________________________\n",
            "dense_28 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 5,645,826\n",
            "Trainable params: 5,645,826\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KcxXcKY-Rw9"
      },
      "source": [
        "#Entrainement du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ncgIAQnAPN3",
        "outputId": "df0babaf-9bb4-4c81-b8f7-2edd8b2af202"
      },
      "source": [
        "model.fit(x_train,  y_train, epochs=8, batch_size=100,verbose =2)"
      ],
      "execution_count": 271,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/8\n",
            "15/15 - 12s - loss: 0.6747 - accuracy: 0.5960\n",
            "Epoch 2/8\n",
            "15/15 - 9s - loss: 0.5053 - accuracy: 0.7767\n",
            "Epoch 3/8\n",
            "15/15 - 9s - loss: 0.2962 - accuracy: 0.8753\n",
            "Epoch 4/8\n",
            "15/15 - 9s - loss: 0.1623 - accuracy: 0.9400\n",
            "Epoch 5/8\n",
            "15/15 - 9s - loss: 0.0771 - accuracy: 0.9747\n",
            "Epoch 6/8\n",
            "15/15 - 9s - loss: 0.0460 - accuracy: 0.9920\n",
            "Epoch 7/8\n",
            "15/15 - 9s - loss: 0.0716 - accuracy: 0.9780\n",
            "Epoch 8/8\n",
            "15/15 - 9s - loss: 0.0505 - accuracy: 0.9940\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2289095f90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 271
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKXq8XMV-WBP"
      },
      "source": [
        "#Evaluation du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-JMbmdtCBJkj",
        "outputId": "55e75feb-e76d-4994-e62c-b48eb999b2a4"
      },
      "source": [
        "model.evaluate(x_test,y_test)\r\n"
      ],
      "execution_count": 272,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 1s 48ms/step - loss: 0.5457 - accuracy: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5457485914230347, 0.7400000095367432]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 272
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LBOfKw01-YYR"
      },
      "source": [
        "#Sauvegarde du modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZC_tyOaIoaIo",
        "outputId": "e30b1a1e-a8f7-46ff-e263-a718fbc5228c"
      },
      "source": [
        "model.save('/content/gdrive/MyDrive/NLP_Projet/models/Model_1')"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/gdrive/MyDrive/NLP_Projet/models/Model_1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cbv1SKF-bEe"
      },
      "source": [
        "# Récupération des commentaires depuis l'API Yelp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9nDKFfBtXdB",
        "outputId": "504f1601-1afe-4522-a6ff-94884c243c3d"
      },
      "source": [
        "api_key='q1HJoEmRMdypie_E6lYwiih0hNfuSatSTQXH6Bh9fnltm30JX4XO1TSCd6NARRVszrs4lMXb7N3i6LWB_UIBEinyG_ah-0expG6GUnzTdUss2gvNQRcJ7fJhK5g2YHYx'\r\n",
        "headers = {'Authorization': 'Bearer %s' % api_key}\r\n",
        "url = \"https://api.yelp.com/v3/businesses/FEVQpbOPOwAPNIgO7D3xxw/reviews\"\r\n",
        "req = requests.get(url, headers=headers)\r\n",
        "data=json.loads(req.text)\r\n",
        "data"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'possible_languages': ['fr', 'en', 'zh', 'pt', 'de', 'it', 'sv', 'ja', 'es'],\n",
              " 'reviews': [{'id': 'qOiuCTz_Gzgmose1GHaAlg',\n",
              "   'rating': 5,\n",
              "   'text': \"Truth be told if it was up to me I'd be giving 4/5 stars, we did order recently and our cheese fries weren't delivered, couldn't speak with anyone from...\",\n",
              "   'time_created': '2020-12-19 07:52:35',\n",
              "   'url': 'https://www.yelp.com/biz/shake-shack-new-york-2?adjust_creative=KzZVmcfbYqCMY9omoha5NA&hrid=qOiuCTz_Gzgmose1GHaAlg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_reviews&utm_source=KzZVmcfbYqCMY9omoha5NA',\n",
              "   'user': {'id': 'FRKnLBnlFiasr1Dc8oOIGQ',\n",
              "    'image_url': 'https://s3-media3.fl.yelpcdn.com/photo/1wm0yjWSw92j_ZsUFZBGzQ/o.jpg',\n",
              "    'name': 'Sarah G.',\n",
              "    'profile_url': 'https://www.yelp.com/user_details?userid=FRKnLBnlFiasr1Dc8oOIGQ'}},\n",
              "  {'id': '7d56A_ObMPHHyywcfhnrUw',\n",
              "   'rating': 5,\n",
              "   'text': 'Happened to be in the city today and not too far from here so I had to stop by and pick up cheese fries (I love those crinkle cuts!) and a shake. Yum. Tbh,...',\n",
              "   'time_created': '2021-02-25 19:56:35',\n",
              "   'url': 'https://www.yelp.com/biz/shake-shack-new-york-2?adjust_creative=KzZVmcfbYqCMY9omoha5NA&hrid=7d56A_ObMPHHyywcfhnrUw&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_reviews&utm_source=KzZVmcfbYqCMY9omoha5NA',\n",
              "   'user': {'id': '77MIRZBZqbQKoonun8qWjQ',\n",
              "    'image_url': 'https://s3-media2.fl.yelpcdn.com/photo/ptL063kjqRUDQ6pny96iqg/o.jpg',\n",
              "    'name': 'Ipsita D.',\n",
              "    'profile_url': 'https://www.yelp.com/user_details?userid=77MIRZBZqbQKoonun8qWjQ'}},\n",
              "  {'id': 'SYykUNBT2dJznMV5PpRnhg',\n",
              "   'rating': 5,\n",
              "   'text': 'Before I moved to NY, my first ever trip to the city was in 2005 - this was when Shake Shack had this one lone original location, and it was an event to go...',\n",
              "   'time_created': '2020-12-12 15:19:49',\n",
              "   'url': 'https://www.yelp.com/biz/shake-shack-new-york-2?adjust_creative=KzZVmcfbYqCMY9omoha5NA&hrid=SYykUNBT2dJznMV5PpRnhg&utm_campaign=yelp_api_v3&utm_medium=api_v3_business_reviews&utm_source=KzZVmcfbYqCMY9omoha5NA',\n",
              "   'user': {'id': 'yw2cJk_SfGZlcoZKEUevxw',\n",
              "    'image_url': 'https://s3-media1.fl.yelpcdn.com/photo/EH2WTffzgKs72GHqa4kn6A/o.jpg',\n",
              "    'name': 'Thomas V.',\n",
              "    'profile_url': 'https://www.yelp.com/user_details?userid=yw2cJk_SfGZlcoZKEUevxw'}}],\n",
              " 'total': 5609}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6dai3p_-k5j"
      },
      "source": [
        "#Pipeline permettant de faire une prédiction en mettant une phrase en entrée"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xbYYiUOtYtSw"
      },
      "source": [
        "\r\n",
        "    \r\n",
        "def pipeline(sentence):\r\n",
        "\r\n",
        "  text_data=pd.DataFrame([sentence], columns = [\"text\"])\r\n",
        "  tokenizer = Tokenizer(num_words=20000, split=\" \")\r\n",
        "  tokenizer.fit_on_texts(text_data[\"text\"].values)\r\n",
        "\r\n",
        "  texte_traité= tokenizer.texts_to_sequences(text_data[\"text\"].values)\r\n",
        "  texte_traité = pad_sequences(texte_traité)\r\n",
        "\r\n",
        "  a=model.predict(texte_traité)\r\n",
        "\r\n",
        "  if a[0][0] < (1/3):\r\n",
        "    print('Negatif')\r\n",
        "    \r\n",
        "  elif  a[0][0] > (2/3): \r\n",
        "    print('Positif')\r\n",
        "    \r\n",
        "  else:\r\n",
        "    print('Neutre')\r\n",
        "\r\n",
        "  return a\r\n",
        "\r\n"
      ],
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRk1dKHL-xG2"
      },
      "source": [
        "#Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UGGzXlNYCOu",
        "outputId": "e8c672f5-4663-4e88-b41a-a268127b15ba"
      },
      "source": [
        "review1 =data[\"reviews\"][0][\"text\"]\r\n",
        "review2=data[\"reviews\"][1][\"text\"]\r\n",
        "review3=data[\"reviews\"][2][\"text\"]\r\n",
        "\r\n",
        "prediction1 = pipeline(review1)\r\n",
        "prediction2 = pipeline(review2)\r\n",
        "prediction3 = pipeline(review3)\r\n",
        "\r\n",
        "\r\n",
        "    \r\n"
      ],
      "execution_count": 276,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 32) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name='embedding_28_input'), name='embedding_28_input', description=\"created by layer 'embedding_28_input'\"), but it was called on an input with incompatible shape (None, 30).\n",
            "Positif\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 32) for input KerasTensor(type_spec=TensorSpec(shape=(None, 32), dtype=tf.float32, name='embedding_28_input'), name='embedding_28_input', description=\"created by layer 'embedding_28_input'\"), but it was called on an input with incompatible shape (None, 34).\n",
            "Positif\n",
            "Positif\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}